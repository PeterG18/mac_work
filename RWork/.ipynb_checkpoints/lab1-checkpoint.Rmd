# ---
# title: "Lab 1"
# author: "Your Full Name"
# date: "2024-09-09"
# output:
#   pdf_document: default
#   html_document:
#     theme: flatly
# editor_options:
#   markdown:
#     wrap: sentence
 ---

 ```{r, eval=F}
 install.packages("devtools")
 library(devtools)

# install package
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("remotes", repos = "http://cran.us.r-project.org")
install.packages("here", repos = "http://cran.us.r-project.org")
install.packages("devtools")

 
# load the necessary libraries
library(tidyverse) #collection of R packages designed for data science
library(here) #helps with filepaths
library(tidyverse)
library(devtools)
library(dplyr)
library(remotes)

here::i_am("lab1.Rmd")

# use the remote install function to call in your data
remotes::install_github("professornaite/critstats", force=TRUE)

# load the `critstats` library
library(critstats)

# update the `critstats` package if needed
# update.packages("critstats")

critstats::true_size

df1 <- critstats::true_size

str(df1)

# check the dimensions of your data
dim(df1)

# view the "top" of your data
head(df1)

# view the data
View(df1)

# Get a glimpse of your data frame
glimpse(df1)

# view the "top" of your data
head(df1)

# view the "bottom" of your data
tail(df1)

# view the top 10 observations
head(df1, n = 10)

# view the bottom 3 observations
tail(df1, n = 3)

# get a summary of your data frame
summary(df1)

# keep only the Country and percent.africa columns
select(df1, Country, percent.africa) 

# keep only the Country and area.sq.mi columns
select(df1, Country, area.sq.mi)

# remove the area.sq.mi variable
select(df1, -area.sq.km)

# remove the listed variables in the data frame
select(df1, -area.sq.km, -area.sq.mi) 

# keep only those rows where the percent.africa value is grater than 30
filter(df1, percent.africa > 30)

# keep only those rows where the percent.africa value is less than 1
filter(df1, percent.africa < 1)

# keep only those rows where percent.africa is less than 10 and greater than 1
filter(df1, percent.africa < 10 & percent.africa > 1)

# keep only those rows where Country is equal to "China"
filter(df1, Country == "China")

# add a new column with a more accurate label for land area estimate (sq mi)
mutate(df1, est.square.miles = df1$area.sq.mi * 1000000) 

# we can create the same output when using the %>% (pipe)
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) 
  
# add a new column with a more accurate label for land area estimate (sq km)
df1 %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000)


# remove the old column; use the pipe command to do both operations at once
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km) # remove the columns we do not want

df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country)  # make the 'C' in country lowercase

df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
  
true_size_modified <- df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
true_size_modified


# call the africa_data_all
critstats::africa_data_all 

??critstats::africa_data_all 

df2 <- critstats::africa_data_all


str(df2)

head(df2)

tail(df2)

View(df2)

summary(df2)

# create a table of the number of observations by year
table(df2$year)

summary(filter(df2, year == 2020))

# gather summary statistics for all variables for year == 2020
df2 %>% 
  filter(year == 2020) %>% 
  summary()
  

# gather summary statistics for all variables for year == 2023
df2 %>% 
  filter(year == 2023) %>% 
  summary()

# create a separate data frame for 2020
data_2020 <- df2 %>% 
  filter(year == 2020)

data_2020 # view the data for 2020

# create a separate data frame for 2023
data_2023 <- df2 %>% 
  filter(year == 2023) %>% 
  relocate(country, year)

data_2023 # view the data for 2023

is.na(data_2020)

is.na(data_2023)

is.na(data_2020$migrants)

sapply(data_2020, function(x) sum(is.na(x)))

View(data_2020)

# mean returns `NA` since there are missing values
mean(data_2020$migrants)
# instruct R to remove missing values from the analysis using `
mean(data_2020$migrants, na.rm = TRUE)

# find the average population in 2020
mean(data_2020$pop)
# find the average percent urban population in 2020
mean(data_2020$urban.pop)

# find the average of median age in 2020
mean(data_2020$med.age)
# check to see missing data in the variable
is.na(data_2020$med.age)
# compute the mean using the na.rm = TRUE
mean(data_2020$med.age, na.rm = TRUE)


median(data_2020$pop)

# filter data to show countries that are below the median
data_2020 %>% 
  filter(pop < median(pop)) %>% 
  select(country, pop)
  
# filter data to show countries that are above the median
data_2020 %>% 
  filter(pop > median(pop)) %>% 
  select(country, pop)

# what does this output tell us about the mode of the med.age variable?
mode(data_2020$med.age) 

# what does this updated output tell us about the mode of the med.age variable?
table(data_2020$med.age) 


# get the maximum value
max(data_2020$pop)

# use pipes to gather details about which country or territory has the max value
data_2020 %>% 
  filter(pop == max(pop)) %>% 
  select(country, pop)
  
# get the minimum value
min(data_2020$pop)

# use pipes to gather details about which country or territory has the min value
data_2020 %>% 
  filter(pop == min(pop)) %>% 
  select(country, pop)
 
 
range(data_2020$pop) 
# generate a new variable call population range that is the maximum minus the minimum value
pop_range_2020 <- max(data_2020$pop) - min(data_2020$pop)
pop_range_2020 # we must call the object back to see its value

# find the IQR for the 2020 population variable
IQR(data_2020$pop)

# find the IQR for the 2020 percent urban population variable
IQR(data_2020$urban.pop)

# find the standard deviation of the 2020 population variable
sd(data_2020$pop)

# find the standard deviation of the 2020 urban population variable
sd(data_2020$urban.pop)

summary(data_2020)

boxplot(data_2020$pop)

hist(data_2020$pop)

stem(data_2020$med.age)

plot(data_2020$med.age)

plot(density(data_2020$pop))

# -----------------------------------------------------------------------------
#Report 1.1

# Some of the main ideas from Vaughan (2018) include Social Cartography, which is the use of maps to show social issues like poverty, disease, and segregation. Another important concept is the Spatial Logic of Society, which looks at how the layout of cities and neighborhoods reflects social structures and how maps can show these patterns. Vaughan also discusses Segregation and Inequality, as well as Visual Rhetoric in Maps, where things like colors and symbols on maps can send certain messages, often reinforcing stereotypes or moral judgments. Maps have also been used as tools for social reform, especially in the 19th century, to address issues related to public health and poverty. Finally, Vaughan emphasizes the Power of Maps and how they are shaped by the social and political context in which they are made, influencing how we understand space, segregation, and inequality.

# These ideas can be applied to modern times by mapping current social and population data to highlight ongoing inequalities. We could use data to look at how changes in population, urban growth, and migration lead to new forms of segregation, similar to what Vaughan discusses about past eras. This can help us understand how social and spatial inequalities still exist today, using maps to reveal these patterns.

# Report 1.2
> df1 %>%
+   mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
+   mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
+   select(-area.sq.mi, -area.sq.km) 

# If the data in true size is correct it is expected that as the square mileage and square kilometers increase so does the percent.africa variable. This expected correlation between the percent.africa and est.square.miles variables proves to be true as the scatterplot image supports this, which should be true as the larger a country is, the larger the percentage of africa will be

# Report 1.3

# There is enough information to confirm if the claims about the size of Africa and the social politics of maps is true, because for example, one would think that north america and even china are almost the same size as africa as it is represented on maps but its not even close as we can see when looking at the size of the land

# Report 1.4

true_size_updated <- true_size_modified %>%
    mutate(proportion = percent.africa / sum(percent.africa))

true_size_updated

# Report 1.5
plot(true_size_updated$proportion, true_size_updated$percent.africa)
title("Peter Gansallo") # Add your first name and last name

# Report 1.6
# The str() function provides us with the requested information most efficiently
str(df2)

# Report 1.7

# The summary function return a text, and not a tibble or dataframe, and the first parameter of the filter function is supposed to be a data fram or tibble.

# Report 1.8
View(data_2020)
sapply(data_2020, function(x) sum(is.na(x)))
View(data_2020)
# Saint Helena is missing Migrants, Fertility rate, and median age values.

# Report 1.9
# instruct R to remove missing values from the analysis using `
two_nvars <- data_2023 %>% 
  select(pop, density)
 
# this shows the min, max, median, and mean for our two chosen numeric variables 
summary(two_nvars)

#check frequency to find mode
table(two_nvars$pop) 
# there is no mode for population


table(two_nvars$density) 
#the modes are 5, 9, 18, 19, 29, 43, 61, 76, 85, 122

# find the IQR for the 2023 population variable
IQR(two_nvars$pop)

# find the standard deviation of the 2023 population variable
sd(two_nvars$pop)

# find the IQR for the 2023 density variable
IQR(two_nvars$density)

# find the standard deviation of the 2023 density variable
sd(two_nvars$density)

# Report 1.10
plot(two_nvars$pop, two_nvars$density)
title("Peter Gansallo") 
