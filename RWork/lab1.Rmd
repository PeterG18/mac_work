---
title: "Lab 1"
author: "Peter Gansallo"
date: "2024-09-24"
output:
  html_document:
    theme: flatly
    self_contained: yes
    mode: self_contained
  pdf_document:
editor_options:
  markdown:
    wrap: sentence
---
 
```{r, eval=F}
install.packages("devtools")
library(devtools)
```

Install the necessary libraries

```{r, eval=F}
# install package
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("remotes", repos = "http://cran.us.r-project.org")
install.packages("here", repos = "http://cran.us.r-project.org")
```

Load the necessary libraries and set path

```{r setup, include=FALSE}
library(tidyverse) # collection of R packages designed for data science
library(here) # helps with filepaths
library(dplyr)
library(remotes)
setwd("~/Desktop/RWork")
here::i_am("lab1.Rmd") # this should match the file name
```

Loading the `critstats` library

```{r, eval=F}
# Use the remote install function to call in your data
# remotes::install_github("professornaite/critstats", force=TRUE)

Loading the `critstats` library
library(critstats)

# update the `critstats` package if needed
# update.packages("critstats")
```

```{r, eval=F}
critstats::true_size
```

## Pre Lab

Assign the true size data frame of critstats to df1

```{r}
df1 <- critstats::true_size
``` 

Provide the structure of the dataframe

```{r}
str(df1)
```

Check the dimensions of your data

```{r}
dim(df1)
```

View the "top" of your data

```{r}
head(df1)
```

View the data

```{r}
#View(df1)
```


Get a glimpse of your data frame

```{r}
#glimpse(df1)
```

View the "top" of your data

```{r}
head(df1)
```

View the "bottom" of your data

```{r}
tail(df1)
```

View the top 10 observations

```{r}
head(df1, n = 10)
```

View the bottom 3 observations

```{r}
tail(df1, n = 3)
```

Get a summary of your data frame

```{r}
summary(df1)
```

Keep only the Country and percent.africa columns

```{r}
select(df1, Country, percent.africa) 
```

Keep only the Country and area.sq.mi columns

```{r}
select(df1, Country, area.sq.mi)
```


Remove the area.sq.mi variable

```{r}
select(df1, -area.sq.km)
```

Remove the listed variables in the data frame

```{r}
select(df1, -area.sq.km, -area.sq.mi) 
```

Keep only those rows where the percent.africa value is grater than 30

```{r}
filter(df1, percent.africa > 30)
```

Keep only those rows where the percent.africa value is less than 1

```{r}
filter(df1, percent.africa < 1)
```

Keep only those rows where percent.africa is less than 10 and greater than 1

```{r}
filter(df1, percent.africa < 10 & percent.africa > 1)
```

Keep only those rows where Country is equal to "China"

```{r}
filter(df1, Country == "China")
```

Add a new column with a more accurate label for land area estimate (sq mi)

```{r}
mutate(df1, est.square.miles = df1$area.sq.mi * 1000000) 
```

We can create the same output when using the %>% (pipe)

```{r}
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) 
```

Add a new column with a more accurate label for land area estimate (sq km)
```{r}
df1 %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000)
```

Remove the old column using different ways; use the pipe command to do both operations at once

```{r}
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km) # remove the columns we do not want

df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country)  # make the 'C' in country lowercase

df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
```

Create new columns, remove old columns, rename a column, and order the columns

```{r}
true_size_modified <- df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
true_size_modified
```

Call the africa_data_all

```{r}
critstats::africa_data_all 
??critstats::africa_data_all 
```

Assign the africa_data_all dataset from critstats to variable df2

```{r}
df2 <- critstats::africa_data_all
```

Play with the basic functions like we did for df1

```{r}
str(df2)

head(df2)

tail(df2)

#View(df2)

summary(df2)
```

Create a table of the number of observations by year

```{r}
table(df2$year)
```

This is a nested function to get the summary of a filtered year

```{r}
summary(filter(df2, year == 2020))
```

Gather summary statistics for all variables for year == 2020

```{r}
df2 %>% 
  filter(year == 2020) %>% 
  summary()
```  

Gather summary statistics for all variables for year == 2023

```{r}
df2 %>% 
  filter(year == 2023) %>% 
  summary()
```

Create a separate data frame for 2020 and 2023

```{r}
data_2020 <- df2 %>% 
  filter(year == 2020)

data_2020 # view the data for 2020

# create a separate data frame for 2023
data_2023 <- df2 %>% 
  filter(year == 2023) %>% 
  relocate(country, year)

data_2023 # view the data for 2023
```

See the values of the data if they are null or not

```{r}
is.na(data_2020)

is.na(data_2023)

is.na(data_2020$migrants)
```

Apply the function sum to get the count of null values

```{r}
sapply(data_2020, function(x) sum(is.na(x)))
```

Mean returns `NA` since there are missing values

```{r}
mean(data_2020$migrants)
```

Instruct R to remove missing values from the analysis

```{r}
mean(data_2020$migrants, na.rm = TRUE)
```

Using the mean function

```{r}
# find the average population in 2020
mean(data_2020$pop)
# find the average percent urban population in 2020
mean(data_2020$urban.pop)

# find the average of median age in 2020
mean(data_2020$med.age)
# check to see missing data in the variable
is.na(data_2020$med.age)
# compute the mean using the na.rm = TRUE
mean(data_2020$med.age, na.rm = TRUE)
```

The median function

```{r}
median(data_2020$pop)
```

Using filter in more ways

```{r}
# filter data to show countries that are below the median
data_2020 %>% 
  filter(pop < median(pop)) %>% 
  select(country, pop)
  
# filter data to show countries that are above the median
data_2020 %>% 
  filter(pop > median(pop)) %>% 
  select(country, pop)
```

Getting the mode of the data frame

```{r}
# what does this output tell us about the mode of the med.age variable?
mode(data_2020$med.age) 

# what does this updated output tell us about the mode of the med.age variable?
table(data_2020$med.age) 
```

Get the maximum value

```{r}
max(data_2020$pop)
```

Taking a deeper look at the dataset

```{r}
# use pipes to gather details about which country or territory has the max value
data_2020 %>% 
  filter(pop == max(pop)) %>% 
  select(country, pop)
  
# get the minimum value
min(data_2020$pop)

# use pipes to gather details about which country or territory has the min value
data_2020 %>% 
  filter(pop == min(pop)) %>% 
  select(country, pop)
```

Getting the ranges

```{r}
range(data_2020$pop) 
# generate a new variable call population range that is the maximum minus the minimum value
pop_range_2020 <- max(data_2020$pop) - min(data_2020$pop)
pop_range_2020 # we must call the object back to see its value
```

IQR and Standard Deviation

```{r}
# find the IQR for the 2020 population variable
IQR(data_2020$pop)

# find the IQR for the 2020 percent urban population variable
IQR(data_2020$urban.pop)

# find the standard deviation of the 2020 population variable
sd(data_2020$pop)

# find the standard deviation of the 2020 urban population variable
sd(data_2020$urban.pop)
```

Making different graphs of the Univariate data

```{r}
boxplot(data_2020$pop)

hist(data_2020$pop)

stem(data_2020$med.age)

plot(data_2020$med.age)

plot(density(data_2020$pop))
```

-----------------------------------------------------------------------------
## Lab Report

### Report 1.1

Some of the main ideas from Vaughan (2018) include Social Cartography, which is the use of maps to show social issues like poverty, disease, and segregation. Another important concept is the Spatial Logic of Society, which looks at how the layout of cities and neighborhoods reflects social structures and how maps can show these patterns. Vaughan also discusses Segregation and Inequality, as well as Visual Rhetoric in Maps, where things like colors and symbols on maps can send certain messages, often reinforcing stereotypes or moral judgments. Maps have also been used as tools for social reform, especially in the 19th century, to address issues related to public health and poverty. Finally, Vaughan emphasizes the Power of Maps and how they are shaped by the social and political context in which they are made, influencing how we understand space, segregation, and inequality.

These ideas can be applied to modern times by mapping current social and population data to highlight ongoing inequalities. We could use data to look at how changes in population, urban growth, and migration lead to new forms of segregation, similar to what Vaughan discusses about past eras. This can help us understand how social and spatial inequalities still exist today, using maps to reveal these patterns.

###  Report 1.2

If the data in true size is correct it's expected that as the square mileage and square kilometers increase so does the percent.africa variable. This is expected because there is a positive correlation between the percent.africa and est.square.miles variables because the larger a country is, the larger the percentage of Africathat country will take up, meaning the percent.africa variable will be larger,which is supported by the scatterplot provided.


### Report 1.3

There is enough information to confirm if the claims about the size of Africa and the social politics of maps are true, because for example, just looking at a map and looking at north america, russia, european countries and even china are almost the same size as africa as it is represented on maps but the proportions of those countries/continents are very misrepresented, because size does create an idea of power, and I believe that's the main reason today the maps are misrepresented

###Top 3 countries with the largest percent size of Africa
#### USA, China and India
```{r}
plot(head(df1$percent.africa, n=3))
```

### Report 1.4

Add a column to true_size data frame, and save to a new variable

```{r}
true_size_updated <- true_size_modified %>%
    mutate(proportion = percent.africa / sum(percent.africa))

true_size_updated
```

### Report 1.5

Confirming I have overwritten to the new variable

```{r}
plot(true_size_updated$proportion, true_size_updated$percent.africa)
title("Peter Gansallo")
```

### Report 1.6

The str() function provides us with each variable and the variable type in the data frame

```{r}
str(df2)
```

### Report 1.7

If we flipped summary and filter this would work from "filter(summary(df2, year == 2020))" to summary(filter(df2, year == 2020)). Because the first parameter of the filter function in this case is supposed to be a data frame, but it's receiving text as a parameter because it reads from the summary function.

Corrected code

```{r}
summary(filter(df2, year == 2020))
```


### Report 1.8

```{r}
#View(data_2020) commented out to knitt
sapply(data_2020, function(x) sum(is.na(x)))
```

After running the code I see Saint Helena is the country missing values which is missing Migrants, Fertility rate, and median age values.

### Report 1.9

Chose Population and Density to be our two variables for univariate analysis

```{r}
two_nvars <- data_2023 %>% 
  select(pop, density)
```

Summary function shows the min, max, median, and mean for our two chosen numeric variables 

```{r}
summary(two_nvars)
```

Check the frequency to find the mode

```{r}
table(two_nvars$pop) 
# We see there is no mode for population
```

Manually look at the table to find the modes

```{r}
table(two_nvars$density) 
#we see that there are multiple modes for this variables which are 5, 9, 18, 19, 29, 43, 61, 76, 85, 122
```

Check and see how the data and values are spread out

```{r}
# find the IQR for the 2023 population variable
IQR(two_nvars$pop)

# find the standard deviation of the 2023 population variable
sd(two_nvars$pop)

# find the IQR for the 2023 density variable
IQR(two_nvars$density)

# find the standard deviation of the 2023 density variable
sd(two_nvars$density)
```

### Report 1.10

Create the univariate plot on population

```{r}
plot(density(two_nvars$pop))
title("Peter Gansallo") 
```

Create the univariate plot on density

```{r}
plot(density(two_nvars$density))
title("Peter Gansallo") 
```